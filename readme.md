# ğŸ¬ Semantic Movie Search Engine

AI-powered **Semantic Search API** built with:

-   ğŸ Python\
-   ğŸŒ Django (REST API)\
-   ğŸ” Elasticsearch 8 (Vector Search)\
-   ğŸ¤– Sentence Transformers (Embeddings)\
-   ğŸ³ Docker

This project implements semantic movie search using transformer
embeddings and Elasticsearch's `dense_vector` with cosine similarity.

------------------------------------------------------------------------

## ğŸš€ Features

-   Semantic search using transformer embeddings\
-   Elasticsearch vector indexing (`dense_vector`)\
-   Clean API responses (no raw ES metadata)\
-   Dockerized multi-container setup\
-   Persistent HuggingFace model cache\
-   Bulk ingestion pipeline\
-   Modular architecture (AI layer separated from API layer)

------------------------------------------------------------------------

## ğŸ§  How It Works

### Data Ingestion Flow

CSV Dataset\
â†“\
Combine fields (title + genres + description)\
â†“\
Generate embedding using SentenceTransformer (384-dim vector)\
â†“\
Store document + embedding in Elasticsearch

### Search Flow

User Query\
â†“\
Convert query to embedding\
â†“\
KNN search in Elasticsearch (cosine similarity)\
â†“\
Return top matched movies

------------------------------------------------------------------------

## ğŸ“ Project Structure

app/

â”œâ”€â”€ manage.py \# Django entry point\
â”œâ”€â”€ config.py \# Central configuration\
â”œâ”€â”€ embedding.py \# Loads AI model & generates embeddings\
â”œâ”€â”€ es_index.py \# Creates Elasticsearch index\
â”œâ”€â”€ search.py \# Vector search logic\
â”œâ”€â”€ ingest.py \# Bulk ingestion script\
â”œâ”€â”€ movies_api/ \# Django project config\
â”œâ”€â”€ search_api/ \# Django REST app\
â”œâ”€â”€ netflix_titles.csv \# Dataset\
â”œâ”€â”€ huggingface_cache/ \# Persisted model cache (ignored in Git)\
â””â”€â”€ elasticsearch-data/ \# Elasticsearch data volume (ignored in Git)

------------------------------------------------------------------------

## ğŸ§  Why huggingface_cache Exists

Transformer models (\~90MB+) are downloaded from Hugging Face.

Without persistence: - Docker rebuild â†’ model redownload\
- Slower startup\
- Network dependency each time

We mount:

./huggingface_cache:/huggingface_cache

And set:

HF_HOME=/huggingface_cache

This ensures: - Model downloads once\
- Cache persists\
- Faster restarts\
- Stable container behavior

------------------------------------------------------------------------

## ğŸ§  Why elasticsearch-data Exists

Elasticsearch stores: - Indexed documents\
- Vector data\
- Lucene index files

We mount:

./elasticsearch-data:/usr/share/elasticsearch/data

So data persists across container restarts.

------------------------------------------------------------------------

## ğŸ›  Setup Instructions

### 1ï¸âƒ£ Clone the Repository

git clone `<your-repo-url>`{=html}\
cd `<project-folder>`{=html}

### 2ï¸âƒ£ Start Docker Services

docker-compose up --build -d

Services: - Elasticsearch â†’ http://localhost:9200\
- Kibana â†’ http://localhost:5601\
- Django API â†’ http://localhost:8000

### 3ï¸âƒ£ Ingest Dataset

docker exec -it semantic_api bash\
python ingest.py

Verify document count:

curl http://localhost:9200/movies/\_count

### 4ï¸âƒ£ Test Search API

POST http://localhost:8000/search/

Example body:

{ "query": "a movie where protagonist gets superpowers" }

------------------------------------------------------------------------

## ğŸ” Elasticsearch Configuration

Using Elasticsearch 8.15.0

Vector field mapping:

"embedding": { "type": "dense_vector", "dims": 384, "index": true,
"similarity": "cosine" }

------------------------------------------------------------------------

## ğŸ¤– AI Model Used

sentence-transformers/all-MiniLM-L6-v2

-   384-dimensional embeddings\
-   Lightweight & CPU-friendly\
-   Optimized for semantic similarity

------------------------------------------------------------------------

## ğŸ§¼ Ignored in Git

elasticsearch-data/\
huggingface_cache/\
**pycache**/\
db.sqlite3

------------------------------------------------------------------------

## ğŸ Conclusion

This project demonstrates:

-   Integration of AI models with search infrastructure\
-   Scalable semantic search architecture\
-   Clean backend design with Django\
-   Production-like Docker setup
